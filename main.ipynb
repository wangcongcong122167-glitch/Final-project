{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e32f2f24-88ea-4ebb-ad72-812621256943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "def load_daily_data(file_path):\n",
    "    p = Path(file_path)\n",
    "    df = pd.read_csv(p, parse_dates=[\"Date\"])\n",
    "    df.set_index(\"Date\", inplace=True)\n",
    "    if df.index.tz is None:\n",
    "        df.index = df.index.tz_localize(\"UTC\")\n",
    "    for col in [\"Close\", \"Adj Close\", \"Open\", \"High\", \"Low\", \"Vol\", \"Volume\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    # Standardize volume column: prefer Volume, then Vol\n",
    "    if \"Volume\" in df.columns:\n",
    "        df[\"volume_raw\"] = df[\"Volume\"]\n",
    "    elif \"Vol\" in df.columns:\n",
    "        df[\"volume_raw\"] = df[\"Vol\"]\n",
    "    else:\n",
    "        df[\"volume_raw\"] = np.nan\n",
    "    return df.sort_index()\n",
    "\n",
    "def load_minute_data(file_paths):\n",
    "    frames = []\n",
    "    for file_path in file_paths:\n",
    "        p = Path(file_path)\n",
    "        df = pd.read_csv(p)\n",
    "        if \"Open time\" not in df.columns:\n",
    "            raise KeyError(f\"{p} missing 'Open time' column\")\n",
    "        df[\"Open time\"] = pd.to_datetime(df[\"Open time\"], utc=True)\n",
    "        df.rename(columns={\"Open time\": \"Date\"}, inplace=True)\n",
    "        for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        df.set_index(\"Date\", inplace=True)\n",
    "        frames.append(df.sort_index())\n",
    "    combined_df = pd.concat(frames).sort_index()\n",
    "    return combined_df\n",
    "\n",
    "def load_announcement_data(file_path):\n",
    "    p = Path(file_path)\n",
    "    if p.suffix.lower() == \".csv\":\n",
    "        df = pd.read_csv(p)\n",
    "    elif p.suffix.lower() == \".xlsx\":\n",
    "        df = pd.read_excel(p)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "    # Automatically detect date column\n",
    "    candidates = [\"Date\", \"Release_Date\", \"Release Date\", \"DATE\", \"Time\", \"Datetime\", \"AnnouncementTime\"]\n",
    "    date_col = None\n",
    "    lower = {c.lower(): c for c in df.columns}\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            date_col = c; break\n",
    "        if c.lower() in lower:\n",
    "            date_col = lower[c.lower()]; break\n",
    "    if date_col is None:\n",
    "        raise KeyError(f\"{p} no date column found, actual columns: {list(df.columns)}\")\n",
    "\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\", utc=True)\n",
    "    df.rename(columns={date_col: \"Date\"}, inplace=True)\n",
    "    df.set_index(\"Date\", inplace=True)\n",
    "    return df.sort_index()\n",
    "\n",
    "# === Change to actual filenames in current directory ===\n",
    "daily_assets = {\n",
    "    \"AZN\": load_daily_data(\"./data/AZN.L_unadjusted.csv\"),\n",
    "    \"BP\": load_daily_data(\"./data/BP.L_unadjusted.csv\"),\n",
    "    \"BTC_USD\": load_daily_data(\"./data/BTC-USD_unadjusted.csv\"),\n",
    "    \"ETH_USD\": load_daily_data(\"./data/ETH-USD_unadjusted.csv\"),\n",
    "    \"HSBA\": load_daily_data(\"./data/HSBA.L_unadjusted.csv\"),\n",
    "    \"FTSE\": load_daily_data(\"./data/^FTSE_unadjusted.csv\"),\n",
    "}\n",
    "\n",
    "btc_minute_files = [f\"./data/BTCUSDT_1m_2024-{month:02d}_unadjusted.csv\" for month in range(1, 13)]\n",
    "eth_minute_files = [f\"./data/ETHUSDT_1m_2024-{month:02d}_unadjusted.csv\" for month in range(1, 13)]\n",
    "\n",
    "minute_assets = {\n",
    "    \"BTCUSDT_1m\": load_minute_data(btc_minute_files),\n",
    "    \"ETHUSDT_1m\": load_minute_data(eth_minute_files),\n",
    "}\n",
    "\n",
    "announcements = {\n",
    "    \"CPI\":  load_announcement_data(\"./data/US_Core_CPI_MoM_2015_2024.xlsx\"),\n",
    "    \"FOMC\": load_announcement_data(\"./data/US_Fed_FOMC_RateDecision_2015_2024.xlsx\"),\n",
    "    \"NFP\":  load_announcement_data(\"./data/US_NFP_2015_2024_simple_K.xlsx\"),\n",
    "}\n",
    "\n",
    "# Save to current directory\n",
    "with open(\"daily_assets.pkl\", \"wb\") as f:\n",
    "    pickle.dump(daily_assets, f)\n",
    "with open(\"minute_assets.pkl\", \"wb\") as f:\n",
    "    pickle.dump(minute_assets, f)\n",
    "with open(\"announcements.pkl\", \"wb\") as f:\n",
    "    pickle.dump(announcements, f)\n",
    "\n",
    "print(\"Data loaded and saved successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff75302-f8cd-4296-afc7-cb3c17595b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\王若禹\\AppData\\Local\\Temp\\ipykernel_45924\\1340334909.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[\"returns\"] = out[\"Close\"].pct_change()\n",
      "C:\\Users\\王若禹\\AppData\\Local\\Temp\\ipykernel_45924\\1340334909.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[\"returns\"] = out[\"Close\"].pct_change()\n",
      "C:\\Users\\王若禹\\AppData\\Local\\Temp\\ipykernel_45924\\1340334909.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[\"returns\"] = out[\"Close\"].pct_change()\n",
      "C:\\Users\\王若禹\\AppData\\Local\\Temp\\ipykernel_45924\\1340334909.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[\"returns\"] = out[\"Close\"].pct_change()\n",
      "C:\\Users\\王若禹\\AppData\\Local\\Temp\\ipykernel_45924\\1340334909.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[\"returns\"] = out[\"Close\"].pct_change()\n",
      "C:\\Users\\王若禹\\AppData\\Local\\Temp\\ipykernel_45924\\1340334909.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out[\"returns\"] = out[\"Close\"].pct_change()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event study complete and results saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load pkl files from current directory\n",
    "with open(\"daily_assets.pkl\", \"rb\") as f:\n",
    "    daily_assets = pickle.load(f)\n",
    "with open(\"minute_assets.pkl\", \"rb\") as f:\n",
    "    minute_assets = pickle.load(f)\n",
    "with open(\"announcements.pkl\", \"rb\") as f:\n",
    "    announcements = pickle.load(f)\n",
    "\n",
    "# Ensure announcement index is UTC-aware\n",
    "for ann_type in announcements:\n",
    "    if announcements[ann_type].index.tz is None:\n",
    "        announcements[ann_type].index = announcements[ann_type].index.tz_localize(\"UTC\")\n",
    "\n",
    "def calculate_metrics(df):\n",
    "    out = df.copy()\n",
    "    out[\"returns\"] = out[\"Close\"].pct_change()\n",
    "    out[\"volatility\"] = out[\"returns\"].rolling(window=5, min_periods=5).std()\n",
    "    # Standardize volume: minute uses Volume, daily uses volume_raw\n",
    "    if \"Volume\" in out.columns:\n",
    "        out[\"volume\"] = out[\"Volume\"]\n",
    "    elif \"volume_raw\" in out.columns:\n",
    "        out[\"volume\"] = out[\"volume_raw\"]\n",
    "    else:\n",
    "        out[\"volume\"] = np.nan\n",
    "    return out\n",
    "\n",
    "processed_daily_data = {k: calculate_metrics(v.copy()) for k, v in daily_assets.items()}\n",
    "processed_minute_data = {k: calculate_metrics(v.copy()) for k, v in minute_assets.items()}\n",
    "\n",
    "def run_event_study_raw(data, announcement_dates, window_type=\"daily\"):\n",
    "    \"\"\"\n",
    "    Return raw abnormal value lists (no t-test here).\n",
    "    daily estimation window [-65,-6], event window [-5,+5];\n",
    "    minute estimation window [-300,-61], event window [-60,+60]\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for ann_type, ann_df in announcement_dates.items():\n",
    "        type_results = {}\n",
    "        for asset_name, df in data.items():\n",
    "            res = {\"abnormal_returns\": [], \"abnormal_volatility\": [], \"abnormal_volume\": []}\n",
    "            for ann_time in ann_df.index:\n",
    "                if window_type == \"daily\":\n",
    "                    est_s, est_e = ann_time - pd.Timedelta(days=65), ann_time - pd.Timedelta(days=6)\n",
    "                    evt_s, evt_e = ann_time - pd.Timedelta(days=5),  ann_time + pd.Timedelta(days=5)\n",
    "                else:\n",
    "                    est_s, est_e = ann_time - pd.Timedelta(minutes=300), ann_time - pd.Timedelta(minutes=61)\n",
    "                    evt_s, evt_e = ann_time - pd.Timedelta(minutes=60),  ann_time + pd.Timedelta(minutes=60)\n",
    "\n",
    "                est = df.loc[(df.index >= est_s) & (df.index <= est_e)]\n",
    "                evt = df.loc[(df.index >= evt_s) & (df.index <= evt_e)]\n",
    "                if est.empty or evt.empty:\n",
    "                    continue\n",
    "\n",
    "                normal_ret = est[\"returns\"].mean()\n",
    "                normal_vol = est[\"volatility\"].mean()\n",
    "                normal_volm = est[\"volume\"].mean()\n",
    "\n",
    "                res[\"abnormal_returns\"].extend((evt[\"returns\"] - normal_ret).dropna().tolist())\n",
    "                res[\"abnormal_volatility\"].extend((evt[\"volatility\"] - normal_vol).dropna().tolist())\n",
    "                res[\"abnormal_volume\"].extend((evt[\"volume\"] - normal_volm).dropna().tolist())\n",
    "            type_results[asset_name] = res\n",
    "        results[ann_type] = type_results\n",
    "    return results\n",
    "\n",
    "# Run and save \"raw abnormal value results\"\n",
    "daily_event_study_results  = run_event_study_raw(processed_daily_data, announcements, window_type=\"daily\")\n",
    "minute_event_study_results = run_event_study_raw(processed_minute_data, announcements, window_type=\"minute\")\n",
    "\n",
    "with open(\"daily_event_study_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(daily_event_study_results, f)\n",
    "with open(\"minute_event_study_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(minute_event_study_results, f)\n",
    "\n",
    "# Also save processed data (for regression use)\n",
    "with open(\"processed_daily_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(processed_daily_data, f)\n",
    "with open(\"processed_minute_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(processed_minute_data, f)\n",
    "\n",
    "print(\"Event study complete and results saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd1f7fb3-9eea-4f48-bd4f-da2de7cf0d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical analysis completed and results saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy import stats\n",
    "\n",
    "with open(\"daily_event_study_results.pkl\", \"rb\") as f:\n",
    "    daily_results = pickle.load(f)\n",
    "with open(\"minute_event_study_results.pkl\", \"rb\") as f:\n",
    "    minute_results = pickle.load(f)\n",
    "\n",
    "def perform_t_test(series_like):\n",
    "    s = pd.Series(series_like, dtype=\"float64\").dropna()\n",
    "    if len(s) == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    t_stat, p_val = stats.ttest_1samp(s, 0.0)\n",
    "    return s.mean(), t_stat, p_val\n",
    "\n",
    "# Daily\n",
    "daily_statistical_results = {}\n",
    "for ann_type, assets_data in daily_results.items():\n",
    "    daily_statistical_results[ann_type] = {}\n",
    "    for asset_name, metrics_data in assets_data.items():\n",
    "        daily_statistical_results[ann_type][asset_name] = {}\n",
    "        for metric_name, abnormal_list in metrics_data.items():\n",
    "            mean_abn, t_stat, p_val = perform_t_test(abnormal_list)\n",
    "            daily_statistical_results[ann_type][asset_name][metric_name] = {\n",
    "                \"mean_abnormal\": mean_abn,\n",
    "                \"t_statistic\": t_stat,\n",
    "                \"p_value\": p_val,\n",
    "            }\n",
    "\n",
    "# Minute\n",
    "minute_statistical_results = {}\n",
    "for ann_type, assets_data in minute_results.items():\n",
    "    minute_statistical_results[ann_type] = {}\n",
    "    for asset_name, metrics_data in assets_data.items():\n",
    "        minute_statistical_results[ann_type][asset_name] = {}\n",
    "        for metric_name, abnormal_list in metrics_data.items():\n",
    "            mean_abn, t_stat, p_val = perform_t_test(abnormal_list)\n",
    "            minute_statistical_results[ann_type][asset_name][metric_name] = {\n",
    "                \"mean_abnormal\": mean_abn,\n",
    "                \"t_statistic\": t_stat,\n",
    "                \"p_value\": p_val,\n",
    "            }\n",
    "\n",
    "with open(\"daily_statistical_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(daily_statistical_results, f)\n",
    "with open(\"minute_statistical_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(minute_statistical_results, f)\n",
    "\n",
    "print(\"Statistical analysis completed and results saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd809662-ea56-4979-ad63-4fa13127e611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression analysis complete and results saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "\n",
    "with open(\"processed_daily_data.pkl\", \"rb\") as f:\n",
    "    processed_daily_data = pickle.load(f)\n",
    "with open(\"processed_minute_data.pkl\", \"rb\") as f:\n",
    "    processed_minute_data = pickle.load(f)\n",
    "with open(\"announcements.pkl\", \"rb\") as f:\n",
    "    announcements_data = pickle.load(f)\n",
    "\n",
    "# Ensure announcement indices are UTC-aware\n",
    "for ann_type in announcements_data:\n",
    "    if announcements_data[ann_type].index.tz is None:\n",
    "        announcements_data[ann_type].index = announcements_data[ann_type].index.tz_localize(\"UTC\")\n",
    "\n",
    "def run_regression_analysis(data, announcement_data, window_type='daily'):\n",
    "    regression_results = {}\n",
    "    for asset_name, df in data.items():\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df = df.sort_index()\n",
    "        # Ensure abnormal_* columns exist (fallback here if not added earlier)\n",
    "        for col in [\"abnormal_returns\", \"abnormal_volatility\", \"abnormal_volume\"]:\n",
    "            if col not in df.columns:\n",
    "                df[col] = df[col.replace(\"abnormal_\", \"\")] - df[col.replace(\"abnormal_\", \"\")].rolling(60).mean()\n",
    "\n",
    "        dependent_vars = ['abnormal_returns', 'abnormal_volatility', 'abnormal_volume']\n",
    "        asset_results = {}\n",
    "\n",
    "        for ann_type, ann_df in announcement_data.items():\n",
    "            event_dummy = pd.Series(0, index=df.index)\n",
    "            for ann_date in ann_df.index:\n",
    "                if window_type == 'daily':\n",
    "                    s, e = ann_date - pd.Timedelta(days=5), ann_date + pd.Timedelta(days=5)\n",
    "                else:\n",
    "                    s, e = ann_date - pd.Timedelta(minutes=60), ann_date + pd.Timedelta(minutes=60)\n",
    "                event_dummy.loc[(event_dummy.index >= s) & (event_dummy.index <= e)] = 1\n",
    "            X = sm.add_constant(event_dummy.rename(\"announcement_dummy\"))\n",
    "\n",
    "            metrics_results = {}\n",
    "            for dep in dependent_vars:\n",
    "                tmp = pd.concat([X, df[dep]], axis=1).dropna()\n",
    "                if tmp.empty:\n",
    "                    metrics_results[dep] = {'coefficient': None, 'p_value': None, 'r_squared': None}\n",
    "                    continue\n",
    "                model = sm.OLS(tmp[dep], tmp[['const', 'announcement_dummy']]).fit()\n",
    "                metrics_results[dep] = {\n",
    "                    'coefficient': model.params.get('announcement_dummy'),\n",
    "                    'p_value': model.pvalues.get('announcement_dummy'),\n",
    "                    'r_squared': model.rsquared\n",
    "                }\n",
    "            asset_results[ann_type] = metrics_results\n",
    "        regression_results[asset_name] = asset_results\n",
    "    return regression_results\n",
    "\n",
    "daily_regression_results  = run_regression_analysis(processed_daily_data, announcements_data, window_type='daily')\n",
    "minute_regression_results = run_regression_analysis(processed_minute_data, announcements_data, window_type='minute')\n",
    "\n",
    "with open('daily_regression_results.pkl', 'wb') as f:\n",
    "    pickle.dump(daily_regression_results, f)\n",
    "with open('minute_regression_results.pkl', 'wb') as f:\n",
    "    pickle.dump(minute_regression_results, f)\n",
    "\n",
    "print(\"Regression analysis complete and results saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "737afabb-9907-4578-a774-5fe56cb88a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All results have been exported to all_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def dict_to_df(data):\n",
    "    \"\"\"Convert a three-level nested dict into a DataFrame\"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        (ann, asset, metric): vals\n",
    "        for ann, assets in data.items()\n",
    "        for asset, metrics in assets.items()\n",
    "        for metric, vals in metrics.items()\n",
    "    }).T\n",
    "    df.index = pd.MultiIndex.from_tuples(df.index, names=[\"Announcement\", \"Asset\", \"Metric\"])\n",
    "    return df\n",
    "\n",
    "# === 1. Statistical results ===\n",
    "with open(\"./daily_statistical_results.pkl\", \"rb\") as f:\n",
    "    daily_stats = pickle.load(f)\n",
    "with open(\"./minute_statistical_results.pkl\", \"rb\") as f:\n",
    "    minute_stats = pickle.load(f)\n",
    "\n",
    "df_daily_stats = dict_to_df(daily_stats)\n",
    "df_minute_stats = dict_to_df(minute_stats)\n",
    "\n",
    "# === 2. Regression results ===\n",
    "with open(\"./daily_regression_results.pkl\", \"rb\") as f:\n",
    "    daily_reg = pickle.load(f)\n",
    "with open(\"./minute_regression_results.pkl\", \"rb\") as f:\n",
    "    minute_reg = pickle.load(f)\n",
    "\n",
    "df_daily_reg = dict_to_df(daily_reg)\n",
    "df_minute_reg = dict_to_df(minute_reg)\n",
    "\n",
    "# === 3. Raw event-study results (abnormal value lists can be very large; not recommended to export directly)\n",
    "# If needed, export only the sample size for each combo\n",
    "with open(\"./daily_event_study_results.pkl\", \"rb\") as f:\n",
    "    daily_event = pickle.load(f)\n",
    "with open(\"./minute_event_study_results.pkl\", \"rb\") as f:\n",
    "    minute_event = pickle.load(f)\n",
    "\n",
    "def dict_to_countdf(data):\n",
    "    df = pd.DataFrame({\n",
    "        (ann, asset, metric): len(vals)\n",
    "        for ann, assets in data.items()\n",
    "        for asset, metrics in assets.items()\n",
    "        for metric, vals in metrics.items()\n",
    "    }, index=[\"N\"]).T\n",
    "    df.index = pd.MultiIndex.from_tuples(df.index, names=[\"Announcement\", \"Asset\", \"Metric\"])\n",
    "    return df\n",
    "\n",
    "df_daily_event_count = dict_to_countdf(daily_event)\n",
    "df_minute_event_count = dict_to_countdf(minute_event)\n",
    "\n",
    "# === 4. Save everything to a single Excel file ===\n",
    "with pd.ExcelWriter(\"all_results.xlsx\") as writer:\n",
    "    df_daily_stats.to_excel(writer, sheet_name=\"Daily_Statistics\")\n",
    "    df_minute_stats.to_excel(writer, sheet_name=\"Minute_Statistics\")\n",
    "    df_daily_reg.to_excel(writer, sheet_name=\"Daily_Regression\")\n",
    "    df_minute_reg.to_excel(writer, sheet_name=\"Minute_Regression\")\n",
    "    df_daily_event_count.to_excel(writer, sheet_name=\"Daily_Event_N\")\n",
    "    df_minute_event_count.to_excel(writer, sheet_name=\"Minute_Event_N\")\n",
    "\n",
    "print(\"✅ All results have been exported to all_results.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ec6b6ee-d797-4294-93ef-ba56fe9c9155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: arch in c:\\users\\王若禹\\appdata\\roaming\\python\\python312\\site-packages (7.2.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in d:\\anaconda3\\lib\\site-packages (from arch) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8 in d:\\anaconda3\\lib\\site-packages (from arch) (1.13.1)\n",
      "Requirement already satisfied: pandas>=1.4 in d:\\anaconda3\\lib\\site-packages (from arch) (2.2.2)\n",
      "Requirement already satisfied: statsmodels>=0.12 in d:\\anaconda3\\lib\\site-packages (from arch) (0.14.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda3\\lib\\site-packages (from pandas>=1.4->arch) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\王若禹\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.4->arch) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda3\\lib\\site-packages (from pandas>=1.4->arch) (2023.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in d:\\anaconda3\\lib\\site-packages (from statsmodels>=0.12->arch) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in d:\\anaconda3\\lib\\site-packages (from statsmodels>=0.12->arch) (24.1)\n",
      "Requirement already satisfied: six in d:\\anaconda3\\lib\\site-packages (from patsy>=0.5.6->statsmodels>=0.12->arch) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install arch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30e1fe2f-ea45-433c-ab53-546f370e1e7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 55\u001b[0m\n\u001b[0;32m     51\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m5\u001b[39m), sharex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax, col, title \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m     53\u001b[0m     axes, ret_cols, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBTC - AR (Return)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETH - AR (Return)\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     54\u001b[0m ):\n\u001b[1;32m---> 55\u001b[0m     plot_by_category(ax, mean_tbl, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOffsetMin\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39mcol, cats\u001b[38;5;241m=\u001b[39mcats)\n\u001b[0;32m     56\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinutes around event\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cats' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===== 1) Read & window =====\n",
    "file = \"./data/EventAligned_BTC_ETH_1m_window_-60_to_120_ET_2024_FULL_cleanNFP.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "df_win = df[df[\"OffsetMin\"].between(-60, 120)].copy()\n",
    "\n",
    "events = [\"CPI\", \"NFP\", \"FOMC\"]\n",
    "ret_cols = [\"BTC_ret_1m\", \"ETH_ret_1m\"]\n",
    "\n",
    "# Volume columns are optional: skip volume plots if missing\n",
    "vol_cols_all = [\"BTC_volume_1m\", \"ETH_volume_1m\"]\n",
    "vol_cols = [c for c in vol_cols_all if c in df.columns]\n",
    "\n",
    "# ===== 2) Utility: safe plotting (only plot categories with data) with dynamic legend =====\n",
    "def plot_by_category(ax, table, x, y, cats, label_title=\"Surprise\"):\n",
    "    plotted = False\n",
    "    for cat in cats:\n",
    "        sub = table[table[\"Category\"] == cat]\n",
    "        if not sub.empty and y in sub:\n",
    "            ax.plot(sub[x], sub[y], marker=\"o\", ms=3, label=cat)\n",
    "            plotted = True\n",
    "    ax.axvline(0, linestyle=\"--\", alpha=0.8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    if plotted:\n",
    "        ax.legend(title=label_title)\n",
    "    return plotted\n",
    "\n",
    "# ===== 3) By event: compute means & plot =====\n",
    "for evt in events:\n",
    "    df_evt = df_win[df_win[\"EventType\"] == evt].copy()\n",
    "    if df_evt.empty:\n",
    "        print(f\"[Note] {evt} has no data in this window; skipped.\")\n",
    "        continue\n",
    "\n",
    "    # (a) Mean table by Surprise × OffsetMin (returns & volume)\n",
    "    mean_tbl = (\n",
    "        df_evt.groupby([\"Category\", \"OffsetMin\"])[ret_cols + vol_cols]\n",
    "              .mean().reset_index()\n",
    "              .sort_values([\"Category\", \"OffsetMin\"])\n",
    "    )\n",
    "\n",
    "    # (b) CAR (cumulative sum of returns)\n",
    "    car_tbl = mean_tbl.copy()\n",
    "    for col in ret_cols:\n",
    "        car_tbl[col + \"_CAR\"] = car_tbl.groupby(\"Category\")[col].cumsum()\n",
    "\n",
    "    # ---- Fig 1: AR (returns) ----\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharex=True)\n",
    "    for ax, col, title in zip(\n",
    "        axes, ret_cols, [\"BTC - AR (Return)\", \"ETH - AR (Return)\"]\n",
    "    ):\n",
    "        plot_by_category(ax, mean_tbl, x=\"OffsetMin\", y=col, cats=cats)\n",
    "        ax.set_title(f\"{evt}: {title}\")\n",
    "        ax.set_xlabel(\"Minutes around event\")\n",
    "        ax.set_ylabel(\"Average 1-min return\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ---- Fig 2: CAR (cumulative returns) ----\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharex=True)\n",
    "    for ax, col, title in zip(\n",
    "        axes, ret_cols, [\"BTC - CAR (Return)\", \"ETH - CAR (Return)\"]\n",
    "    ):\n",
    "        plot_by_category(ax, car_tbl, x=\"OffsetMin\", y=col+\"_CAR\", cats=cats)\n",
    "        ax.set_title(f\"{evt}: {title}\")\n",
    "        ax.set_xlabel(\"Minutes around event\")\n",
    "        ax.set_ylabel(\"Cumulative average return\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ---- Fig 3: Volume (1-min average) ----\n",
    "    if vol_cols:\n",
    "        fig, axes = plt.subplots(1, len(vol_cols), figsize=(7*len(vol_cols), 5), sharex=True)\n",
    "        # Handle single-subplot case where axes is not iterable\n",
    "        if len(vol_cols) == 1:\n",
    "            axes = [axes]\n",
    "        titles = [c.split(\"_\")[0] + \" - Volume (1m avg)\" for c in vol_cols]\n",
    "        for ax, col, title in zip(axes, vol_cols, titles):\n",
    "            plot_by_category(ax, mean_tbl, x=\"OffsetMin\", y=col, cats=cats)\n",
    "            ax.set_title(f\"{evt}: {title}\")\n",
    "            ax.set_xlabel(\"Minutes around event\")\n",
    "            ax.set_ylabel(\"Average 1-min volume\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"[Note] Volume columns {vol_cols_all} not found in file; volume plots skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5aabc1-4f95-42f4-9cc9-b215d2bdaa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[保存] C:\\Users\\王若禹\\Desktop\\CPI_BTC_AR.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\CPI_ETH_AR.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\CPI_BTC_CAR.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\CPI_ETH_CAR.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\CPI_BTC_Volume.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\CPI_ETH_Volume.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\NFP_BTC_AR.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\NFP_ETH_AR.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\NFP_BTC_CAR.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\NFP_ETH_CAR.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\NFP_BTC_Volume.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\NFP_ETH_Volume.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\FOMC_BTC_AR.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\FOMC_ETH_AR.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\FOMC_BTC_CAR.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\FOMC_ETH_CAR.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\FOMC_BTC_Volume.png\n",
      "[保存] C:\\Users\\王若禹\\Desktop\\FOMC_ETH_Volume.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===== 0) Desktop path =====\n",
    "desktop = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "\n",
    "# ===== 1) Read & window =====\n",
    "file = \"./data/EventAligned_BTC_ETH_1m_window_-60_to_120_ET_2024_FULL_cleanNFP.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Keep only the [-60, 120] window\n",
    "df_win = df[df[\"OffsetMin\"].between(-60, 120)].copy()\n",
    "\n",
    "events  = [\"CPI\", \"NFP\", \"FOMC\"]\n",
    "cats    = [\"Above\", \"Below\", \"Equal\"]\n",
    "\n",
    "# Return & volume columns (use your original column names)\n",
    "ret_cols = [\"BTC_ret_1m\", \"ETH_ret_1m\"]\n",
    "vol_cols_all = [\"BTC_volume_1m\", \"ETH_volume_1m\"]\n",
    "vol_cols = [c for c in vol_cols_all if c in df.columns]  # auto-detect existence\n",
    "\n",
    "# Asset name mapping (for filenames & titles)\n",
    "asset_map = {\n",
    "    \"BTC_ret_1m\": \"BTC\",\n",
    "    \"ETH_ret_1m\": \"ETH\",\n",
    "    \"BTC_volume_1m\": \"BTC\",\n",
    "    \"ETH_volume_1m\": \"ETH\",\n",
    "}\n",
    "\n",
    "# ===== 2) Plot as-is: line by category (keep markers) =====\n",
    "def plot_by_category(ax, table, x, y, cats, label_title=\"Surprise\"):\n",
    "    \"\"\"\n",
    "    Plot lines by category on ax (original method: small circle markers). \n",
    "    Returns whether anything was plotted (to control legend visibility).\n",
    "    \"\"\"\n",
    "    plotted = False\n",
    "    for cat in cats:\n",
    "        sub = table[table[\"Category\"] == cat]\n",
    "        if (not sub.empty) and (y in sub.columns):\n",
    "            ax.plot(sub[x], sub[y], marker=\"o\", ms=3, label=cat)  # keep original style\n",
    "            plotted = True\n",
    "    ax.axvline(0, linestyle=\"--\", alpha=0.8)   # event timestamp\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    if plotted:\n",
    "        ax.legend(title=label_title)\n",
    "    return plotted\n",
    "\n",
    "# ===== 3) By event: compute means & generate/save plots one by one =====\n",
    "for evt in events:\n",
    "    df_evt = df_win[df_win[\"EventType\"] == evt].copy()\n",
    "    if df_evt.empty:\n",
    "        print(f\"[Note] {evt} has no data in this window, skipped.\")\n",
    "        continue\n",
    "\n",
    "    # (a) Mean table by Surprise × OffsetMin (returns & volume)\n",
    "    mean_tbl = (\n",
    "        df_evt.groupby([\"Category\", \"OffsetMin\"])[ret_cols + vol_cols]\n",
    "              .mean()\n",
    "              .reset_index()\n",
    "              .sort_values([\"Category\", \"OffsetMin\"])\n",
    "    )\n",
    "\n",
    "    # (b) CAR (cumulative sum of returns)\n",
    "    car_tbl = mean_tbl.copy()\n",
    "    for col in ret_cols:\n",
    "        car_tbl[col + \"_CAR\"] = car_tbl.groupby(\"Category\")[col].cumsum()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Fig 1: AR (returns) — one for BTC, one for ETH\n",
    "    # -----------------------------\n",
    "    for col in ret_cols:\n",
    "        asset = asset_map[col]\n",
    "        fig, ax = plt.subplots(figsize=(12, 4))  # stretch x-axis\n",
    "        plot_by_category(ax, mean_tbl, x=\"OffsetMin\", y=col, cats=cats)\n",
    "        ax.set_title(f\"{evt}: {asset} - AR (Return)\")\n",
    "        ax.set_xlabel(\"Minutes around event\")\n",
    "        ax.set_ylabel(\"Average 1-min return\")\n",
    "        plt.tight_layout()\n",
    "        out_path = os.path.join(desktop, f\"{evt}_{asset}_AR.png\")\n",
    "        plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(f\"[Saved] {out_path}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Fig 2: CAR (cumulative returns) — one for BTC, one for ETH\n",
    "    # -----------------------------\n",
    "    for col in ret_cols:\n",
    "        asset = asset_map[col]\n",
    "        fig, ax = plt.subplots(figsize=(12, 4))\n",
    "        plot_by_category(ax, car_tbl, x=\"OffsetMin\", y=col + \"_CAR\", cats=cats)\n",
    "        ax.set_title(f\"{evt}: {asset} - CAR (Return)\")\n",
    "        ax.set_xlabel(\"Minutes around event\")\n",
    "        ax.set_ylabel(\"Cumulative average return\")\n",
    "        plt.tight_layout()\n",
    "        out_path = os.path.join(desktop, f\"{evt}_{asset}_CAR.png\")\n",
    "        plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(f\"[Saved] {out_path}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Fig 3: Volume (1-min average) — if columns exist, one for BTC and one for ETH\n",
    "    # -----------------------------\n",
    "    if vol_cols:\n",
    "        for vcol in vol_cols:\n",
    "            asset = asset_map[vcol]\n",
    "            fig, ax = plt.subplots(figsize=(20, 4))\n",
    "            plot_by_category(ax, mean_tbl, x=\"OffsetMin\", y=vcol, cats=cats)\n",
    "            ax.set_title(f\"{evt}: {asset} - Volume (1m avg)\")\n",
    "            ax.set_xlabel(\"Minutes around event\")\n",
    "            ax.set_ylabel(\"Average 1-min volume\")\n",
    "            plt.tight_layout()\n",
    "            out_path = os.path.join(desktop, f\"{evt}_{asset}_Volume.png\")\n",
    "            plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "            print(f\"[Saved] {out_path}\")\n",
    "    else:\n",
    "        print(f\"[Note] Volume columns {vol_cols_all} not found; volume plots skipped.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0605ebdc-9df6-4b8b-a050-a5d67c94337a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
